{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90616fc",
   "metadata": {},
   "source": [
    "Here, ANN model is trained on mel feature calculated using librosa library. \n",
    "Mel feature contains both frequency and time aspects of the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8188b522",
   "metadata": {},
   "source": [
    "### These are all imports required in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f60ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile as wav\n",
    "import pandas as pd\n",
    "import os, pathlib, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D,Flatten, Dense, Dropout\n",
    "from keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "import scipy\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "# from sklearn.metrics import multilabel_confusion_matrix\n",
    "from IPython import display\n",
    "# from livelossplot import PlotLossesKeras\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b59cee",
   "metadata": {},
   "source": [
    "### Place your dataset in the datas directory in the following format:\n",
    "\n",
    "- Copy the dataset from data directory\n",
    "- data contains data that is of 2/3/5 seconds interval. Choose the dataset of particular interval of interest.\n",
    "- E.g. if you want to train the model on 2 seconds interval data, copy directories from 'data_2_sec' and place it in datas folder in following format:\n",
    "\n",
    "datas\n",
    "\n",
    "    |-IVR\n",
    "        |-ivr.wav\n",
    "        |-ivr1.wav\n",
    "        |-ivr2.wav\n",
    "        |.........\n",
    "\n",
    "    |-Music\n",
    "        |-music.wav\n",
    "        |-music1.wav\n",
    "        |-music2.wav\n",
    "        |.........\n",
    "\n",
    "    |-Speech\n",
    "        |-speech.wav\n",
    "        |-speech2.wav\n",
    "        |-speech3.wav\n",
    "        |........."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1add9dad",
   "metadata": {},
   "source": [
    "### here we get the root directory and join it with the dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = pathlib.Path(__name__).parent.absolute()\n",
    "directory_path = os.path.join(base_dir,'datas')\n",
    "directory_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385a295",
   "metadata": {},
   "source": [
    "### feature extraction (extract mel feature)\n",
    "- here, first iteration is performed on the subdirectories in the datas so as to get the labels of the files\n",
    "- in the second iteration, all the files are processed in that subdirectory\n",
    "- if file ends with '.wav' it is loaded using librosa at sample rate 8000 and then melspectrogram is calculated\n",
    "- feature and label are added to the lists respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcda06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = []\n",
    "labels = []\n",
    "for folder_name in os.listdir(directory_path):\n",
    "    folder_path = os.path.join(directory_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        \n",
    "        label = folder_name\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            if file_name.lower().endswith('.wav'):\n",
    "                audio, sr = librosa.load(file_path, sr=8000)\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr )\n",
    "                if mel_spectrogram.shape != (128,79):\n",
    "                    print(mel_spectrogram.shape,file_path)\n",
    "                else:\n",
    "                    feature_data.append(mel_spectrogram)\n",
    "                    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c940638",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data =np.stack(feature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7697f6",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dded5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.array(pd.get_dummies(labels))\n",
    "label = label.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50316479",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ec4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, label\n",
    ", test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ede473",
   "metadata": {},
   "source": [
    "### model creation & training\n",
    "- ANN (sequential) model is used\n",
    "- optimizer is adam, loss used: categorical cross entropy as more than 2 classes used\n",
    "- early stopping (of patience 3) to stop training if accuracy stagnates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87cebe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train[0].shape))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))  \n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48217334",
   "metadata": {},
   "source": [
    "- model is trained on 30 epochs, batch size of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8417f1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "88/88 [==============================] - 11s 114ms/step - loss: 5.0530 - accuracy: 0.5130 - val_loss: 1.3964 - val_accuracy: 0.7148\n",
      "Epoch 2/30\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 2.8305 - accuracy: 0.6639 - val_loss: 1.7136 - val_accuracy: 0.6267\n",
      "Epoch 3/30\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.8766 - accuracy: 0.7045 - val_loss: 0.8958 - val_accuracy: 0.8238\n",
      "Epoch 4/30\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 1.2059 - accuracy: 0.7917 - val_loss: 0.7343 - val_accuracy: 0.8484\n",
      "Epoch 5/30\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.8714 - accuracy: 0.8195 - val_loss: 0.8103 - val_accuracy: 0.8397\n",
      "Epoch 6/30\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 0.8098 - accuracy: 0.8302 - val_loss: 0.7045 - val_accuracy: 0.8462\n",
      "Epoch 7/30\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7821 - accuracy: 0.8544 - val_loss: 0.6187 - val_accuracy: 0.8628\n",
      "Epoch 8/30\n",
      "40/88 [============>.................] - ETA: 4s - loss: 0.7321 - accuracy: 0.8414"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3526e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ann_statistical_mel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e32e18a",
   "metadata": {},
   "source": [
    "### model evaluation\n",
    "- model is evaluated by plotting train, validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e66b3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, ':', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c05c2e4",
   "metadata": {},
   "source": [
    "- model predicts the labels from X_test and then it is compared with the actual labels\n",
    "- a confusion matrix is plotted using seaborn to output the model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52c464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "mat = confusion_matrix(y_test.argmax(axis=1), y_predicted.argmax(axis=1))\n",
    "class_labels = ['IVR', 'Music', 'Speech']\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('Actual label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fee31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
